#The HTTP 403 Forbidden error indicates that you don't have permission to access the requested URL. 
#The website you're trying to scrape may have implemented security measures to prevent automated access to its content.
#then download manually

import requests
from bs4 import BeautifulSoup
import os

def is_excel_file(url):
    return url.endswith('.xlsx') or url.endswith('.xls')

def download_file(url, local_dir):
    response = requests.get(url)
    response.raise_for_status()
    filename = os.path.join(local_dir, url.split('/')[-1])
    with open(filename, 'wb') as file:
        file.write(response.content)


url = "https://idx.co.id/id/perusahaan-tercatat/laporan-keuangan-dan-tahunan/"  # Replace with the actual website URL

response = requests.get(url)
response.raise_for_status()

soup = BeautifulSoup(response.content, 'html.parser')

local_dir = '/Users/nesyfitria/Documents'
if not os.path.exists(local_dir):
    os.makedirs(local_dir)

links = soup.find_all('a')

for link in links:
    href = link.get('href')
    if href and is_excel_file(href):
        file_url = url + href if href.startswith('/') else href
        download_file(file_url, local_dir)
        print(f"Downloaded: {file_url}")

print("All Excel files downloaded successfully!")


